{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Assignment No. 2: Part 2 (Theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the homework you are to solve several simple theoretical problems related to machine learning algorithms.\n",
    "* For every separate problem you can get only 0 points or maximal points for this problem. There are **NO INTERMEDIATE scores**.\n",
    "* Your solution must me **COMPLETE**, i.e. contain all required formulas/proofs/detailed explanations.\n",
    "* You must write your solution for any problem right after the words **YOUR SOLUTION**. Attaching pictures of your handwriting is allowed, but **highly discouraged**.\n",
    "## $\\LaTeX$ in Jupyter\n",
    "Jupyter has constantly improving $\\LaTeX$ support. Below are the basic methods to\n",
    "write **neat, tidy, and well typeset** equations in your notebooks:\n",
    "* to write an **inline** equation use \n",
    "```markdown\n",
    "$ you latex equation here $\n",
    "```\n",
    "* to write an equation, that is **displayed on a separate line** use \n",
    "```markdown\n",
    "$$ you latex equation here $$\n",
    "```\n",
    "* to write a **block of equations** use \n",
    "```markdown\n",
    "\\begin{align}\n",
    "    left-hand-side\n",
    "        &= right-hand-side on line 1\n",
    "        \\\\\n",
    "        &= right-hand-side on line 2\n",
    "        \\\\\n",
    "        &= right-hand-side on the last line\n",
    "\\end{align}\n",
    "```\n",
    "The **ampersand** (`&`) aligns the equations horizontally and the **double backslash**\n",
    "(`\\\\`) creates a new line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1. Bayesian methods (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a dataset $D =(X,y) =\\{(x_i,y_i)\\}^m_{i=1}$, $x_i \\in \\mathbb{R}^d$, $y_i\\in\\mathbb{R}$ it is known, that \n",
    "$$y_i = w^T x_i + \\epsilon$$\n",
    "\n",
    "where $\\epsilon \\sim N(0,\\sigma^2)$, $w  \\sim N(0,\\alpha I)$ . Suppose that $X^T X =I$, where $I$ is the identity matrix. Derive MAP estimation for $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of a data point:\n",
    "$$y_i \\sim N(w^T x_i,\\sigma^2)$$\n",
    "\n",
    "Data sample $D$ likelihood:\n",
    "$$p(D| w) = \\prod_{i=1}^{m} \\frac{1}{\\sqrt{2\\pi}\\sigma} exp\\bigg(-\\frac{(y_i - w^T x_i)^2}{2\\sigma^2}\\bigg)$$\n",
    "\n",
    "Posterior distribution of $w$:\n",
    "$$p(w|D)\\varpropto p(D|w)p(w) = C \\cdot exp\\bigg(-\\frac{(y_i - w^T x_i)^2}{2\\sigma^2}\\bigg) exp\\bigg(-\\frac{w^T\\cdot w}{2\\alpha}\\bigg)$$\n",
    "\n",
    "Log-posterior distribution of $w$:\n",
    "$$\\mathcal{L}_{MAP} = log\\bigg(p(w|D)\\bigg) = -\\frac{1}{2\\sigma^2} \\sum_{i=1}^m (y_i- w^T x_i)^2 - \\frac{1}{2\\alpha} \\sum_{i=1}^{d} w_i^2 + const = $$\n",
    "\n",
    "$$= -\\frac{1}{2\\sigma^2}\\bigg( \\sum_{i=1}^m (y_i- w^T x_i)^2 + \\frac{\\sigma^2}{\\alpha} \\sum_{i=1}^{d} w_i^2 \\bigg) + const = $$\n",
    "\n",
    "$$= -\\frac{1}{2\\sigma^2}\\bigg((Y-Xw)^T(Y-Xw) + \\lambda w^T w \\bigg) + const \\longrightarrow  \\max_{w}$$\n",
    "where $\\lambda = \\frac{\\sigma^2}{\\alpha}$\n",
    "\n",
    "Let minimize the next function:\n",
    "\n",
    "$$-\\mathcal{L}_{MAP} = \\frac{m}{2\\sigma^2}\\bigg((Y-Xw)^T(Y-Xw) + \\lambda w^T w \\bigg) \\longrightarrow \\min_{w}$$\n",
    "\n",
    "$$- \\frac{\\partial}{\\partial w} \\mathcal{L}_{MAP} = \\frac{\\partial}{\\partial w} \\frac{1}{2\\sigma^2}\\bigg( (Y-Xw)^T(Y-Xw) + \\lambda w^T w\\bigg) = \\frac{1}{2\\sigma^2} \\frac{\\partial}{\\partial w}\\bigg( Y^T Y - Y^T X w - w^T X^T Y + w^T X^T X w + \\lambda w^T w \\bigg) = $$\n",
    "\n",
    "$$= \\frac{1}{2\\sigma^2} \\frac{\\partial}{\\partial w}\\bigg( Y^T Y - Y^T X w - w^T X^T Y + w^T X^T X w + \\lambda w^T w \\bigg) = \\frac{1}{2\\sigma^2} \\bigg( 2 X^T(Xw - Y) + 2\\lambda w \\bigg) = \\frac{1}{\\sigma^2} \\bigg( X^T(Xw - Y) + \\lambda w \\bigg) = $$\n",
    "\n",
    "$$= \\frac{1}{\\sigma^2} \\bigg( w - X^TY + \\lambda w \\bigg) = \\frac{1}{\\sigma^2} \\bigg( (\\lambda+1) w - X^TY \\bigg) =   \\bigg(\\alpha^{-1} + \\sigma^{-2}\\bigg) w -  \\sigma^{-2}X^TY $$\n",
    "\n",
    "$$\\bigg(\\alpha^{-1} + \\sigma^{-2}\\bigg) w -  \\sigma^{-2}X^TY = 0$$\n",
    "\n",
    "$$ w = \\bigg(\\alpha^{-1} + \\sigma^{-2}\\bigg)^{-1} \\sigma^{-2}X^TY =\\bigg(\\sigma^2\\alpha^{-1} + 1\\bigg)^{-1} X^TY $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2. Gaussian Processes 1 (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\sigma_n(\\mathbf{x}_*)$ be a predictive variance at point $\\mathbf{x}_*$ of a Gaussian Process $f_n$ with zero mean and covariance $k(\\cdot,\\cdot)$ that was built using first $n$ training points.\n",
    "Prove that for $\\forall \\mathbf{x}_*$ it holds\n",
    "$$\n",
    "    \\sigma_{n}(\\mathbf{x}_*) \\leq \\sigma_{n-1}(\\mathbf{x}_*).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3. Gaussian Processes 2 (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider you have gaussian distribution on $R$ with zero mean and differentiable by arguments covariation funtion $k(x, \\tilde{x})$.Get an expression for the correlation between the implementation of a Gaussian process  $y(x) âˆ¼ GP (0, k(x, x ^{\\prime}))$ and its derivative $\\frac{\\partial y(\\tilde x)}{\\partial \\tilde x}$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your solution\n",
    "Let's prove some expressions:\n",
    "$$\\frac{\\partial}{\\partial z}\\mathbb{E}y(x)y(z) = \\lim_{\\Delta z \\to 0} \\frac{1}{\\Delta z} \\bigg(\\mathbb{E}y(x)y(z+\\Delta z) - \\mathbb{E}y(x)y(z)\\bigg) =\n",
    "\\lim_{\\Delta z \\to 0}\\mathbb{E} \\bigg(\\frac{y(x)y(z+\\Delta z) - y(x)y(z)}{\\Delta z}\\bigg) = \\mathbb{E}y(x)y'(z)$$\n",
    "\n",
    "If $\\mathbb{E}y(x) = 0$, then $\\mathbb{E} y'(z) = \\frac{\\partial}{\\partial z} \\mathbb{E} y(z) = 0$.\n",
    "\n",
    "\n",
    "$$cov(y(x), z(x')) = \\mathbb{E} y(x) y'(z) - \\mathbb{E} y(x) \\mathbb{E} y(z) = \\mathbb{E} y(x) y'(z) = \n",
    "\\frac{\\partial}{\\partial z} \\mathbb{E} y(x) y(z) = \\frac{\\partial }{\\partial z}K(x, z)$$\n",
    "\n",
    "$$\\mathbb{D} y(x) = \\mathbb{E} y^2(x) + \\bigg( \\mathbb{E} y(x) \\bigg)^2 = \\mathbb{E} y(x) y(x) = K(x, x)$$\n",
    "\n",
    "$$\\mathbb{D} y'(z) = \\mathbb{E} (y'(z))^2 + \\bigg( \\mathbb{E} y'(z) \\bigg)^2 = \n",
    "\\mathbb{E} \\left( \\frac{\\partial y(z)}{\\partial z} \\right)^2 = \n",
    "\\mathbb{E} \\left( \\frac{\\partial }{\\partial z} y(z) \\frac{\\partial }{\\partial z} y(z) \\right) =\n",
    "\\frac{\\partial^2 }{\\partial z^2} \\mathbb{E} y(z) y(z) = \n",
    "\\frac{\\partial^2 }{\\partial z^2} K(z, z)$$\n",
    "\n",
    "$$\\rho(y(x), y'(z)) =\\frac{cov(y(x), y'(z))}{\\sqrt{\\mathbb{D}y(x) \\mathbb{D}y'(z)}} = \\frac{\\partial K(x, z)}{\\partial z}  \\bigg(K(x, x) \\frac{\\partial^2 }{\\partial z^2} K(z, z)\\bigg)^{-0.5}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4. Kernel theory (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $K(x, x'):\\mathcal{X}\\times \\mathcal{X}\\rightarrow \\mathbb{R}$ be a PDS kernel,\n",
    "and $\\phi\\colon \\mathcal{X} \\to \\mathcal{H}$ its <b>unknown </b> feature mapping. For $x,x'\\in\\mathcal{X}$ derive the formula for the **distance** between $\n",
    "\\phi(x)$ and $\\phi(x')$ in $\\mathcal{H}$.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that dim $\\phi(x)=n$ and $\\phi(x) = \\bigg(\\phi_1(x), \\phi_2(x), \\cdots, \\phi_n(x)\\bigg)$.\n",
    "\n",
    "\n",
    "$$K(x, x') = \\phi(x)\\phi^T(x') = \\sum_{i=1}^{n} \\phi_i(x)\\phi_i(x')$$\n",
    "\n",
    "$$d\\bigg(\\phi(x), \\phi(x')\\bigg) = \\sqrt{\\sum_{i=1}^n \\bigg(\\phi_i(x) - \\phi_i(x')\\bigg)^2} = \\sqrt{\\sum_{i=1}^n \\phi_i^2(x) - 2\\phi_i^2(x)\\phi_i^2(x') + \\phi_i^2(x')} = \\sqrt{K(x, x) -2K(x, x') + K(x', x')}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5. Naive Gradient Boosting Regression (1 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a regression dataset, consisting of 5 samples with 1-dimensional feature vector $X$ and scalar target vector $y \\in \\mathbb{R}$:\n",
    "\n",
    "|  x   |  y   | \n",
    "|:----:|:----:| \n",
    "|  10  |  1   | \n",
    "|  32  |  9   | \n",
    "|  46  |  13  | \n",
    "|  54  |  16  | \n",
    "|  63  |  23  | \n",
    "\n",
    "In this task you are asked to implement **3 steps of Gradient Boosting Regression** with decision tree stumps as the learners $h_0, h_1, h_2$. \n",
    "\n",
    "In order to complete this task:\n",
    "1. Refer to the slides on naive boosting for regression in **Lecture 8**.\n",
    "2. Assume that the initial model $f_0$ is the mean of the target vector $y$\n",
    "3. According to the algorithm on the boosting approach for regression from **1.**, compute the residuals\n",
    "4. Manually, find a suitable split among the $x_i$ for each decision tree weak model $h_t(X)$, which minimizes the loss function:\n",
    "\n",
    "$$L_{\\text{split_i}} = \\frac{\\text{Var}_{left\\_split}*N_{1} + \\text{Var}_{right\\_split}*N_{2}}{N_{1}+N_{2}}$$\n",
    "\n",
    "where  $\\text{Var}$ is the variance of the values contained in each leaf, $N_1$ is the number of target values $y$ in the left leaf, $N_{2}$ - in the right leaf\n",
    "\n",
    "5. Perform the Gradient Boosting step on the ensemble model $f_t$ with the resulting decision tree stump predictions (assume that the learning rate $lr=1.0$).\n",
    "\n",
    "**Note on Decision Tree Stumps:** A decision tree stump is a decision tree, which consists only of the root and its immediate leaves. In case of this task, at each iteration you are asked to consider 5 different variants of the decision tree stumps $h_t^i$ - one variant for each of the split candidates $x_i$. You should choose the variant that minimizes the loss written above. The two leaves of the tree are formed according to the rule:\n",
    "\n",
    "```python\n",
    "if x_i < split:\n",
    "    target_value -> left leaf\n",
    "elif x_i >= split:\n",
    "    target_value -> right leaf\n",
    "```\n",
    "**HINT:** Think about what should be `target_value` equal to in case of Gradient Boosting Regression.\n",
    "\n",
    "The prediction of decision tree stump $h_t(x_i)$ is the mean of the values of the according leaf.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The task**:\n",
    "\n",
    "* Fill in the table - round the values of table up to the second digit after decimal point:\n",
    "\n",
    "\n",
    "|   x  |   y  |$f_0$|$$y - f_0$$|$L$|$h_0$|$f_1$|$$y-f_1$$|$L$|$h_1$|$f_2$|$$y - f_2$$|$L$|$h_2$|$F_3$|\n",
    "|------|------|-----|-----------|---|-----|-----|---------|---|-----|-----|-----------|---|-----|-----|\n",
    "|  10  |  1   |  0  |    0      | 0 |  0  |  0  |    0    | 0 |  0  |  0  |    0      | 0 |  0  |  0  | \n",
    "|  32  |  9   |  0  |    0      | 0 |  0  |  0  |    0    | 0 |  0  |  0  |    0      | 0 |  0  |  0  |\n",
    "|  46  |  13  |  0  |    0      | 0 |  0  |  0  |    0    | 0 |  0  |  0  |    0      | 0 |  0  |  0  |\n",
    "|  54  |  16  |  0  |    0      | 0 |  0  |  0  |    0    | 0 |  0  |  0  |    0      | 0 |  0  |  0  |\n",
    "|  63  |  23  |  0  |    0      | 0 |  0  |  0  |    0    | 0 |  0  |  0  |    0      | 0 |  0  |  0  |\n",
    "\n",
    "\n",
    "where $L$ is the loss, calculated by the formula for decision tree stumps above, for each of the 5 split variants of the decision tree stump at each iteration\n",
    "* Write down the splits (the feature values) you have found for each of the tree stumps\n",
    "\n",
    "* Insert the predictions of the full ensemble model and the split values, you have achieved after 3 iterations into the plotting cell below (**COPY AND PASTE** the last column from the table above and the splits list to the plotting cell below, instead of **#your solution**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L(values):\n",
    "    values = np.asarray(values)\n",
    "    m = len(values)\n",
    "    L = []\n",
    "\n",
    "    for i in range(m):\n",
    "        left_var = 0 if len(values[:i]) == 0 else np.var(values[:i])\n",
    "        L_val = (i*left_var + (m-i)*np.var(values[i:])) / m\n",
    "\n",
    "        L.append(L_val)\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statistics import mean \n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x   y\n",
       "0  10   1\n",
       "1  32   9\n",
       "2  46  13\n",
       "3  54  16\n",
       "4  63  23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([10, 32, 46, 54, 63])\n",
    "y = np.array([1, 9, 13, 16, 23])\n",
    "\n",
    "data = pd.DataFrame(data={'x': x, 'y':y})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>f0</th>\n",
       "      <th>y-f0</th>\n",
       "      <th>L1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>53.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>20.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>16</td>\n",
       "      <td>12.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>19.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "      <td>12.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>25.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x   y    f0  y-f0     L1\n",
       "0  10   1  12.4 -11.4  53.44\n",
       "1  32   9  12.4  -3.4  20.95\n",
       "2  46  13  12.4   0.6  16.93\n",
       "3  54  16  12.4   3.6  19.83\n",
       "4  63  23  12.4  10.6  25.35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['f0'] = np.ones(len(data.y))*data.y.mean()\n",
    "data['y-f0'] = data['y'] - data['f0']\n",
    "data['L1'] = np.round(compute_L(data['y'].values), 2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksandr.belov/work/tools/anaconda3/envs/u_env/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>f0</th>\n",
       "      <th>y-f0</th>\n",
       "      <th>L1</th>\n",
       "      <th>h0</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>53.44</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>20.95</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.93</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>16</td>\n",
       "      <td>12.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>19.83</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "      <td>12.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>25.35</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x   y    f0  y-f0     L1    h0     f1\n",
       "0  10   1  12.4 -11.4  53.44 -7.40   5.00\n",
       "1  32   9  12.4  -3.4  20.95 -7.40   5.00\n",
       "2  46  13  12.4   0.6  16.93  4.93  17.33\n",
       "3  54  16  12.4   3.6  19.83  4.93  17.33\n",
       "4  63  23  12.4  10.6  25.35  4.93  17.33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_min1 = np.argmin(data['L1'].values)\n",
    "data['h0'] = np.zeros(5)\n",
    "data['h0'].iloc[:L_min1] = data['y-f0'].iloc[:L_min1].mean()\n",
    "data['h0'].iloc[L_min1:] = data['y-f0'].iloc[L_min1:].mean()\n",
    "data['h0'] = np.round(data['h0'], 2)\n",
    "data['f1'] = data['f0'] + data['h0']\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>f0</th>\n",
       "      <th>y-f0</th>\n",
       "      <th>L1</th>\n",
       "      <th>h0</th>\n",
       "      <th>f1</th>\n",
       "      <th>y-f1</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>53.44</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>16.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>20.95</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.93</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>16.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>16</td>\n",
       "      <td>12.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>19.83</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>13.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "      <td>12.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>25.35</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x   y    f0  y-f0     L1    h0     f1  y-f1     L2\n",
       "0  10   1  12.4 -11.4  53.44 -7.40   5.00 -4.00  16.93\n",
       "1  32   9  12.4  -3.4  20.95 -7.40   5.00  4.00  12.93\n",
       "2  46  13  12.4   0.6  16.93  4.93  17.33 -4.33  16.93\n",
       "3  54  16  12.4   3.6  19.83  4.93  17.33 -1.33  13.80\n",
       "4  63  23  12.4  10.6  25.35  4.93  17.33  5.67   8.90"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y-f1'] = data['y']- data['f1']\n",
    "data['L2'] = np.round(compute_L(data['y-f1'].values), 2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>f0</th>\n",
       "      <th>y-f0</th>\n",
       "      <th>L1</th>\n",
       "      <th>h0</th>\n",
       "      <th>f1</th>\n",
       "      <th>y-f1</th>\n",
       "      <th>L2</th>\n",
       "      <th>h1</th>\n",
       "      <th>f2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>53.44</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>16.93</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>20.95</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.93</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.93</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>16.93</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>15.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>16</td>\n",
       "      <td>12.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>19.83</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>13.80</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>15.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "      <td>12.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>25.35</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.90</td>\n",
       "      <td>5.67</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x   y    f0  y-f0     L1    h0     f1  y-f1     L2    h1     f2\n",
       "0  10   1  12.4 -11.4  53.44 -7.40   5.00 -4.00  16.93 -1.41   3.59\n",
       "1  32   9  12.4  -3.4  20.95 -7.40   5.00  4.00  12.93 -1.41   3.59\n",
       "2  46  13  12.4   0.6  16.93  4.93  17.33 -4.33  16.93 -1.41  15.92\n",
       "3  54  16  12.4   3.6  19.83  4.93  17.33 -1.33  13.80 -1.41  15.92\n",
       "4  63  23  12.4  10.6  25.35  4.93  17.33  5.67   8.90  5.67  23.00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_min2 = np.argmin(data['L2'].values)\n",
    "data['h1'] = np.zeros(5)\n",
    "data['h1'].iloc[:L_min2] = data['y-f1'].iloc[:L_min2].mean()\n",
    "data['h1'].iloc[L_min2:] = data['y-f1'].iloc[L_min2:].mean()\n",
    "data['h1'] = np.round(data['h1'], 2)\n",
    "data['f2'] = data['f1'] + data['h1']\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>f0</th>\n",
       "      <th>y-f0</th>\n",
       "      <th>L1</th>\n",
       "      <th>h0</th>\n",
       "      <th>f1</th>\n",
       "      <th>y-f1</th>\n",
       "      <th>L2</th>\n",
       "      <th>h1</th>\n",
       "      <th>f2</th>\n",
       "      <th>y-f2</th>\n",
       "      <th>L3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>53.44</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>16.93</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>3.59</td>\n",
       "      <td>-2.59</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>20.95</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.93</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>3.59</td>\n",
       "      <td>5.41</td>\n",
       "      <td>7.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.93</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>16.93</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>15.92</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>7.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>16</td>\n",
       "      <td>12.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>19.83</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>13.80</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>15.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "      <td>12.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>25.35</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.90</td>\n",
       "      <td>5.67</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x   y    f0  y-f0     L1    h0     f1  y-f1     L2    h1     f2  y-f2  \\\n",
       "0  10   1  12.4 -11.4  53.44 -7.40   5.00 -4.00  16.93 -1.41   3.59 -2.59   \n",
       "1  32   9  12.4  -3.4  20.95 -7.40   5.00  4.00  12.93 -1.41   3.59  5.41   \n",
       "2  46  13  12.4   0.6  16.93  4.93  17.33 -4.33  16.93 -1.41  15.92 -2.92   \n",
       "3  54  16  12.4   3.6  19.83  4.93  17.33 -1.33  13.80 -1.41  15.92  0.08   \n",
       "4  63  23  12.4  10.6  25.35  4.93  17.33  5.67   8.90  5.67  23.00  0.00   \n",
       "\n",
       "     L3  \n",
       "0  8.90  \n",
       "1  7.23  \n",
       "2  7.57  \n",
       "3  8.90  \n",
       "4  8.90  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y-f2'] = data['y'] - data['f2']\n",
    "data['L3'] = np.round(compute_L(data['y-f2'].values), 2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>f0</th>\n",
       "      <th>y-f0</th>\n",
       "      <th>L1</th>\n",
       "      <th>h0</th>\n",
       "      <th>f1</th>\n",
       "      <th>y-f1</th>\n",
       "      <th>L2</th>\n",
       "      <th>h1</th>\n",
       "      <th>f2</th>\n",
       "      <th>y-f2</th>\n",
       "      <th>L3</th>\n",
       "      <th>h2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>53.44</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>16.93</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>3.59</td>\n",
       "      <td>-2.59</td>\n",
       "      <td>8.90</td>\n",
       "      <td>-2.59</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>20.95</td>\n",
       "      <td>-7.40</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.93</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>3.59</td>\n",
       "      <td>5.41</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.64</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>16.93</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>16.93</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>15.92</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>7.57</td>\n",
       "      <td>0.64</td>\n",
       "      <td>16.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>16</td>\n",
       "      <td>12.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>19.83</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>13.80</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>15.92</td>\n",
       "      <td>0.08</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.64</td>\n",
       "      <td>16.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>23</td>\n",
       "      <td>12.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>25.35</td>\n",
       "      <td>4.93</td>\n",
       "      <td>17.33</td>\n",
       "      <td>5.67</td>\n",
       "      <td>8.90</td>\n",
       "      <td>5.67</td>\n",
       "      <td>23.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.64</td>\n",
       "      <td>23.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x   y    f0  y-f0     L1    h0     f1  y-f1     L2    h1     f2  y-f2  \\\n",
       "0  10   1  12.4 -11.4  53.44 -7.40   5.00 -4.00  16.93 -1.41   3.59 -2.59   \n",
       "1  32   9  12.4  -3.4  20.95 -7.40   5.00  4.00  12.93 -1.41   3.59  5.41   \n",
       "2  46  13  12.4   0.6  16.93  4.93  17.33 -4.33  16.93 -1.41  15.92 -2.92   \n",
       "3  54  16  12.4   3.6  19.83  4.93  17.33 -1.33  13.80 -1.41  15.92  0.08   \n",
       "4  63  23  12.4  10.6  25.35  4.93  17.33  5.67   8.90  5.67  23.00  0.00   \n",
       "\n",
       "     L3    h2     F3  \n",
       "0  8.90 -2.59   1.00  \n",
       "1  7.23  0.64   4.23  \n",
       "2  7.57  0.64  16.56  \n",
       "3  8.90  0.64  16.56  \n",
       "4  8.90  0.64  23.64  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_min3 = np.argmin(data['L3'].values)\n",
    "data['h2'] = np.zeros(5)\n",
    "data['h2'].iloc[:L_min3] = data['y-f2'].iloc[:L_min3].mean()\n",
    "data['h2'].iloc[L_min3:] = data['y-f2'].iloc[L_min3:].mean()\n",
    "data['h2'] = np.round(data['h2'], 2)\n",
    "data['F3'] = data['f2'] + data['h2']\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.arange(np.min(x), np.max(x)+1)\n",
    "def plot_tree(x,F,stumps):\n",
    "    \n",
    "    x_r = []\n",
    "    f_r = []\n",
    "    stmps = [0] + stumps + [np.inf]\n",
    "    for st in range(1,len(stmps)):\n",
    "        x_r.extend([list(group) for k, group in groupby(x_range, lambda x: x < stmps[st] and x >= stmps[st-1]) if k])\n",
    "        f_r.append([f_i for f_i, x_ii in zip(F,x) if x_ii < stmps[st] and x_ii >= stmps[st-1]])\n",
    "    F_to_plot = []\n",
    "    for ft in range(len(f_r)):\n",
    "        #assert len(f_r) == len(x_r)\n",
    "        if len(f_r[ft]) == 1:\n",
    "            F_to_plot.extend([f_r[ft][0]]*len(x_r[ft]))\n",
    "        elif len(f_r[ft]) > 1:\n",
    "            F_to_plot.extend([mean(f_r[ft])]*len(x_r[ft]))\n",
    "    return F_to_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOTTING CELL##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#note that the order of F(x_i) should be corresponding to the order of x_i in the table\n",
    "\n",
    "############ INSERT YOUR SOLUTION HERE###############\n",
    "F3 = data['F3'].values\n",
    "splits = [data['x'][L_min1], data['x'][L_min2], data['x'][L_min3]]\n",
    "\n",
    "boosted_F_plot = plot_tree(x, F3, stumps = list(np.sort(splits)))\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(x,y, label = 'original')\n",
    "ax.scatter(x, F3, label = 'predicted')\n",
    "\n",
    "ax.plot(x_range,boosted_F_plot,'--', linewidth=2, label = 'composite function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6. AdaBoost (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following cases,explain how AdaBoost, as given in **Lecture 7**, will treat a weak hypothesis $h_t$ with weighted error $N_t(h_t , w_t )$. Also, in each case, explain why this behavior takes place.\n",
    "1. $N_t = \\frac{1}{2}$\n",
    "2. $N_t > \\frac{1}{2}$\n",
    "3. $N_t = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly show that $0 \\leq N(h_t, \\tilde{w}_t) \\leq 1$\n",
    "$$ N(h_t, \\tilde{w}_t) = \\sum_{i=1}^m \\tilde{w}_{i, t} 1_{\\{y_i h_t(x) \\leq 0\\}}$$\n",
    "$$\\sum_{i=1}^m \\tilde{w}_{i, t} = 1$$\n",
    "1. If $y_i h_t(x) == -1$ is True for all $i$, then $N(h_t, \\tilde{w}_t) = 1$;\n",
    "2. If $y_i h_t(x) == 1$ is False for all $i$, then $N(h_t, \\tilde{w}_t) = 0$;\n",
    "3. $0 < N(h_t, \\tilde{w}_t) < 1$ overwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\alpha_t = \\frac{1}{2} log \\bigg( \\frac{1 - N(h_t, \\tilde{w}_t)}{N(h_t, \\tilde{w}_t)}\\bigg)$$\n",
    "\n",
    "$$\\tilde{w}_{i, t+1} = \\tilde{w}_{i, t}\\cdot exp(-\\alpha_t y_i h_t(x))$$\n",
    "\n",
    "### 1. $N_t = \\frac{1}{2}$\n",
    "\n",
    "In this case $\\alpha_t = 0$.\n",
    "And\n",
    "$$\\tilde{w}_{i, t+1} = \\tilde{w}_{i, t} \\cdot exp(- 0 \\cdot y_i h_t(x)) = \\tilde{w}_{i, t} $$\n",
    "\n",
    "It means that after $t$-th step AdaBoost will not be trained further and we should stop the training.\n",
    "\n",
    "\n",
    "### 2. $N_t > \\frac{1}{2}$\n",
    "\n",
    "In this case $\\alpha_t < 0$.\n",
    "\n",
    "#### 2.1. $y_i h_t(x) = -1$\n",
    "\n",
    "$$\\tilde{w}_{i, t+1} = \\tilde{w}_{i, t} \\cdot exp(- \\alpha_t \\cdot y_i h_t(x)) =\\tilde{w}_{i, t} \\cdot exp( \\alpha_t)= C \\cdot \\tilde{w}_{i, t} $$\n",
    "\n",
    "where $C < 1$. It means that we will decrease the weight of a mispredicted sample for $h_{t+1}(x)$.\n",
    "\n",
    "#### 2.2. $y_i h_t(x) = 1$\n",
    "$$\\tilde{w}_{i, t+1} = \\tilde{w}_{i, t} \\cdot exp(- \\alpha_t \\cdot y_i h_t(x)) = \\tilde{w}_{i, t} \\cdot exp(- \\alpha_t )= C \\cdot \\tilde{w}_{i, t} $$\n",
    "\n",
    "where $C > 1$. It means that we will increase the weight of a correct predicted sample for $h_{t+1}(x)$.\n",
    "\n",
    "### 3. $N_t = 0$\n",
    "\n",
    "$$\\alpha_t = \\frac{1}{2} \\bigg(log(1 - N(h_t, \\tilde{w}_t)) - logN(h_t, \\tilde{w}_t)\\bigg)$$\n",
    "\n",
    "$$\\lim_{N \\to +0} \\alpha_t = \\lim_{N \\to +0} \\frac{1}{2} \\bigg(log(1 - N(h_t, \\tilde{w}_t)) - logN(h_t, \\tilde{w}_t)\\bigg) = +\\infty$$\n",
    "\n",
    "#### 3.1. $y_i h_t(x) = -1$\n",
    "\n",
    "$$\\tilde{w}_{i, t+1} = \\tilde{w}_{i, t} \\cdot exp(- \\alpha_t \\cdot y_i h_t(x)) = \\tilde{w}_{i, t} \\cdot exp( \\alpha_t)$$\n",
    "\n",
    "$$\\lim_{N \\to +0} \\tilde{w}_{i, t+1} = \\lim_{N \\to +0} \\tilde{w}_{i, t} \\cdot exp( \\alpha_t) = +\\infty$$\n",
    "\n",
    "It means that weight of a mispredicted sample will leads to $+\\infty$ and $h_{t+1}(x)$ will be overfited for that sample.\n",
    "\n",
    "#### 3.2. $y_i h_t(x) = 1$\n",
    "\n",
    "$$\\tilde{w}_{i, t+1} = \\tilde{w}_{i, t} \\cdot exp(- \\alpha_t \\cdot y_i h_t(x)) = \\tilde{w}_{i, t} \\cdot exp( -\\alpha_t)$$\n",
    "\n",
    "$$\\lim_{N \\to +0} \\tilde{w}_{i, t+1} = \\lim_{N \\to +0} \\tilde{w}_{i, t} \\cdot exp( -\\alpha_t) = 0$$\n",
    "\n",
    "It means that weight of a correct predicted sample will leads to $0$ and $h_{t+1}(x)$ will not take it into classification loss at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "We should not use $h_t(x)$ such that  $N(h_t, \\tilde{w}_t) \\geq 0.5$, overwise we will get incorrect model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
